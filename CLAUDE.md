# Claude AI Command Reference for crosssecmom2

## CRITICAL: ALWAYS cd to the correct directory first!

```powershell
cd D:\REPOSITORY\morias\Quant\strategies\crosssecmom2
```

## Command Syntax

The main.py script uses `--step` NOT `--backtest` or other variations.

### Valid Commands

```powershell
# 1. Feature Engineering ONLY (generates panel data)
python main.py --step feature_eng

# 2. Backtest ONLY (requires existing panel data)
python main.py --step backtest --model supervised_binned

# 3. Run EVERYTHING (feature_eng + backtest + analysis)
python main.py --step all --model supervised_binned
# OR (default is 'all')
python main.py --model supervised_binned

# 4. Analysis ONLY (requires existing results CSV)
python main.py --step analyze
```

### Model Options
- `supervised_binned` (default) - Uses decision tree binning
- `momentum_rank` - Simple momentum ranking

## Current Configuration (as of 2025-11-24)

```python
# UniverseConfig
min_adv_percentile: 0.50       # 50th percentile (STRICT)
min_data_quality: 0.90          # 90% non-NaN features (STRICT)
equity_only: True               # Equity ETFs only

# FeatureConfig
enable_winsorization: False     # DISABLED - hurts performance
winsorization_n_sigma: 2.5      # (only if enabled)

# ComputeConfig
parallelize_backtest: True      # Parallel execution enabled
```

## File Locations

```
Data Directory: D:\REPOSITORY\Data\crosssecmom2\

Key Files:
- cs_momentum_features.parquet     # Panel data (generated by feature_eng)
- cs_momentum_results_YYYYMMDD_HHMMSS.csv  # Timestamped results
- cs_momentum_results.csv          # Latest results (symlink)
```

## Common Workflows

### Fresh Run from Scratch (MANDATORY for validation)
```powershell
# STEP 1: Clear ALL cache (MANDATORY)
cd D:\REPOSITORY\Data\crosssecmom2
Remove-Item cs_momentum_features.parquet -ErrorAction SilentlyContinue
Remove-Item cs_momentum_results*.csv -ErrorAction SilentlyContinue
Remove-Item accounting_debug_log.csv -ErrorAction SilentlyContinue
Remove-Item -Recurse -Force plots -ErrorAction SilentlyContinue

# STEP 2: Verify cache is cleared
Get-ChildItem | Where-Object { $_.Name -like 'cs_momentum*' -or $_.Name -like 'accounting*' }
# Should return NOTHING or only input files (etf_universe*.csv, MACRO_*.csv)

# STEP 3: Return to strategy directory
cd D:\REPOSITORY\morias\Quant\strategies\crosssecmom2

# STEP 4: Verify configuration
python -c "from config import get_default_config; c = get_default_config(); print(f'ADV: {c.universe.min_adv_percentile}'); print(f'Data Quality: {c.universe.min_data_quality}'); print(f'Winsorization: {c.features.enable_winsorization}')"

# STEP 5: Run feature engineering
python main.py --step feature_eng

# STEP 6: Run backtest
python main.py --step backtest --model supervised_binned

# OR run both together:
# python main.py --step all --model supervised_binned
```

### Backtest Only (with existing panel)
```powershell
cd D:\REPOSITORY\morias\Quant\strategies\crosssecmom2
python main.py --step backtest --model supervised_binned
```

### Feature Engineering Only
```powershell
cd D:\REPOSITORY\morias\Quant\strategies\crosssecmom2
python main.py --step feature_eng
```

## Troubleshooting

### "No such option: --step"
❌ **WRONG:** `cd D:\REPOSITORY\Quant` (parent directory)  
✅ **RIGHT:** `cd D:\REPOSITORY\morias\Quant\strategies\crosssecmom2`

### Parallel Processing Errors (Windows)
If you see joblib/loky errors with "Unknown ELBU" or "ntdll.dll":
1. Open `config.py`
2. Set `parallelize_backtest: bool = False` in `ComputeConfig`
3. Re-run

### Feature Panel Not Found
```powershell
# Check if panel exists
Test-Path "D:\REPOSITORY\Data\crosssecmom2\cs_momentum_features.parquet"

# If False, run feature engineering first
cd D:\REPOSITORY\morias\Quant\strategies\crosssecmom2
python main.py --step feature_eng
```

## Performance Expectations

### Feature Engineering
- Time: ~40 seconds
- Output: 233,508 rows × 96 columns (~100 MB parquet file)
- Tickers: 116 ETFs in full universe

### Backtest (Sequential)
- Time: ~5 minutes (47 periods @ 6.5s each)
- Tickers per period: 10-18 (depends on filters)
- Output: CSV with period-by-period results

### Backtest (Parallel)
- Time: ~2-3 minutes (depends on CPU cores)
- May crash on Windows with joblib errors

## Configuration Changes

### To disable winsorization
In `config.py`, `FeatureConfig`:
```python
enable_winsorization: bool = False  # Set to False
```

### To change ADV filter
In `config.py`, `UniverseConfig`:
```python
min_adv_percentile: float = 0.50  # 0.30 = relaxed, 0.50 = strict
```

### To change data quality filter
In `config.py`, `UniverseConfig`:
```python
min_data_quality: float = 0.90  # 0.80 = relaxed, 0.90 = strict
```

## CRITICAL TESTING RULES

### NO SHORTCUTS - REAL DATA ONLY

**Every test MUST follow these rules:**

1. **ALWAYS clear cache before validation runs**
   ```powershell
   cd D:\REPOSITORY\Data\crosssecmom2
   Remove-Item cs_momentum_features.parquet -ErrorAction SilentlyContinue
   Remove-Item cs_momentum_results*.csv -ErrorAction SilentlyContinue
   Remove-Item accounting_debug_log.csv -ErrorAction SilentlyContinue
   ```

2. **NO mock data, NO synthetic data, NO helper tests**
   - ❌ Don't create fake data to "test quickly"
   - ❌ Don't use small synthetic datasets for validation
   - ❌ Don't write tests that self-validate without real pipeline execution
   - ✅ ONLY use real data
   - ✅ ONLY validate against actual backtest results

3. **ALWAYS regenerate from scratch for validation**
   - ❌ Don't trust cached panel data during development
   - ❌ Don't assume results are correct if they come from cache
   - ✅ Delete cache → Run feature_eng → Run backtest → Verify results
   - ✅ Run the FULL pipeline to prove reproducibility

4. **NO self-fulfilling validation**
   - ❌ Don't write tests that just check "did code run without error?"
   - ❌ Don't validate by reading back what you just wrote
   - ✅ Validate by comparing results to known ground truth
   - ✅ Check actual win rates, returns, and metrics against targets

5. **Documentation reflects ACTUAL results**
   - ❌ Don't document aspirational results
   - ❌ Don't claim validation without evidence
   - ✅ Document what actually happened in real backtests
   - ✅ Show reproducibility with independent runs

### Why This Matters

**Past mistakes:**
- Claimed winsorization worked (it didn't - code was buggy)
- Documented 55.32% win rate (actual was 46.81%)
- Said Phase 0 validated (it didn't - cached data masked bugs)
- Trusted helper functions that self-validated without real execution

**Trust is earned through:**
- Running full pipeline from scratch
- Clearing cache before every validation
- Using only real data from real sources
- Proving reproducibility with independent runs

## Common Mistakes to AVOID

1. ❌ Running from wrong directory (`D:\REPOSITORY\Quant`)
2. ❌ Using `--backtest` instead of `--step backtest`
3. ❌ Forgetting `--model supervised_binned`
4. ❌ Not clearing cache when testing config changes
5. ❌ Running backtest without generating features first
6. ❌ Using cached data during development/validation
7. ❌ Writing tests with mock/synthetic data
8. ❌ Trusting results without clearing cache first

## Quick Reference Card

```
ALWAYS START HERE:
cd D:\REPOSITORY\morias\Quant\strategies\crosssecmom2

FRESH RUN:
python main.py --model supervised_binned

FEATURE ONLY:
python main.py --step feature_eng

BACKTEST ONLY:
python main.py --step backtest --model supervised_binned

CLEAR CACHE:
cd D:\REPOSITORY\Data\crosssecmom2
Remove-Item cs_momentum_features.parquet, cs_momentum_results*.csv
```

---
**Last Updated:** 2025-11-24  
**By:** Claude
